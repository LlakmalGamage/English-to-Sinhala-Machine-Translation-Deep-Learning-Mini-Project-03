{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LlakmalGamage/English-to-Sinhala-Machine-Translation-Deep-Learning-Mini-Project-03/blob/main/translator_English_Sinhala_version_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0ZG1jv6QSn3"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DAQyTcsEQSn4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d0wtq3B3QSn6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dataset_path=\"dataset_version_1.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SbXphiEpQSn7"
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv(dataset_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pnHOhO8BQSn7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "import csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "04BL8ZnsQSn7",
        "outputId": "4e2b274a-a507-4672-97e0-263ed3a569cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   english           sinhala\n",
              "0      Go.             යන්න.\n",
              "1      Hi.             හායි.\n",
              "2     Run!           දුවන්න!\n",
              "3     Run.           දුවන්න.\n",
              "4     Who?             කවුද?\n",
              "5    Fire!             ගිනි!\n",
              "6    Help!             උදව්!\n",
              "7    Jump!           පනින්න!\n",
              "8    Jump.           පනින්න.\n",
              "9    Stop!         නවත්වන්න!\n",
              "10   Wait!             ඉන්න!\n",
              "11   Wait.             ඉන්න.\n",
              "12  Go on.     ඉදිරියට යන්න.\n",
              "13  Hello!         ආයුබෝවන්!\n",
              "14  I ran.        මම දිව්වා.\n",
              "15  I try.  මම උත්සාහ කරනවා.\n",
              "16  I won!        මම දිනුවා!\n",
              "17  Oh no!           ඔහ් නෑ!\n",
              "18  Relax.     සන්සුන් වන්න.\n",
              "19  Smile.            සිනහව."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f10f9ce1-dab9-4ced-9f1c-463b20577e8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>sinhala</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>යන්න.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>හායි.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>දුවන්න!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run.</td>\n",
              "      <td>දුවන්න.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who?</td>\n",
              "      <td>කවුද?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>ගිනි!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Help!</td>\n",
              "      <td>උදව්!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>පනින්න!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>පනින්න.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>නවත්වන්න!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>ඉන්න!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Wait.</td>\n",
              "      <td>ඉන්න.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Go on.</td>\n",
              "      <td>ඉදිරියට යන්න.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>ආයුබෝවන්!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I ran.</td>\n",
              "      <td>මම දිව්වා.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I try.</td>\n",
              "      <td>මම උත්සාහ කරනවා.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>I won!</td>\n",
              "      <td>මම දිනුවා!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Oh no!</td>\n",
              "      <td>ඔහ් නෑ!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Relax.</td>\n",
              "      <td>සන්සුන් වන්න.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Smile.</td>\n",
              "      <td>සිනහව.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f10f9ce1-dab9-4ced-9f1c-463b20577e8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f10f9ce1-dab9-4ced-9f1c-463b20577e8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f10f9ce1-dab9-4ced-9f1c-463b20577e8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-583db062-26ce-4ea7-be66-02ce17bf18d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-583db062-26ce-4ea7-be66-02ce17bf18d2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-583db062-26ce-4ea7-be66-02ce17bf18d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 28906,\n  \"fields\": [\n    {\n      \"column\": \"english\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28906,\n        \"samples\": [\n          \"Kick the door in.\",\n          \"Tom fell in love with his best friend's girlfriend.\",\n          \"People always want to blame someone else for all their problems.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sinhala\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27822,\n        \"samples\": [\n          \"\\u0db8\\u0db8 \\u0da7\\u0dca\\u0dc0\\u0dd2\\u0da7\\u0dbb\\u0dca \\u0db4\\u0dcf\\u0dc0\\u0dd2\\u0da0\\u0dca\\u0da0\\u0dd2 \\u0d9a\\u0dbb\\u0db1\\u0dc0\\u0dcf.\",\n          \"\\u0db8\\u0db8 \\u0db8\\u0d9c\\u0dda \\u0dc3\\u0dcf\\u0daf\\u0dba\\u0da7 \\u0db8\\u0dd2\\u0db1\\u0dd2\\u0dc3\\u0dd4\\u0db1\\u0dca \\u0daf\\u0ddc\\u0dc5\\u0ddc\\u0dc3\\u0dca \\u0daf\\u0dd9\\u0db1\\u0dd9\\u0d9a\\u0dca \\u0d86\\u0dbb\\u0dcf\\u0db0\\u0db1\\u0dcf \\u0d9a\\u0dc5 \\u0db1\\u0db8\\u0dd4\\u0dad\\u0dca \\u0dba\\u0db8\\u0dd9\\u0d9a\\u0dd4\\u0da7 \\u0db4\\u0dd0\\u0db8\\u0dd2\\u0dab\\u0dd2\\u0dba \\u0db1\\u0ddc\\u0dc4\\u0dd0\\u0d9a\\u0dd2 \\u0dc0\\u0dd2\\u0dba.\",\n          \"\\u0db8\\u0db8 \\u0dc3\\u0dd9\\u0dbd\\u0ddd \\u0dc3\\u0dd9\\u0dbd\\u0dca\\u0dbd\\u0db8\\u0dca \\u0d9a\\u0dbb\\u0db1\\u0dc0\\u0dcf.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df1.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o5XBj0NQSn7",
        "outputId": "c7843b5f-e1ee-4da2-df12-a5fef63a1dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can't view Flash content on an iPad. However, you can easily email yourself the URLs of these web pages and view that content on your regular computer when you get home.\n",
            "A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\n",
            "No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\n",
            "In 1969, Roger Miller recorded a song called \"You Don't Want My Love.\" Today, this song is better known as \"In the Summer Time.\" It's the first song he wrote and sang that became popular.\n",
            "A child who is a native speaker usually knows many things about his or her language that a non-native speaker who has been studying for years still does not know and perhaps will never know.\n",
            "There are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.\n",
            "There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college education.\n",
            "A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\n",
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
          ]
        }
      ],
      "source": [
        "first_column_values_last_10_rows=df1['english'].tail(10)\n",
        "\n",
        "\n",
        "paragraph = '\\n'.join(first_column_values_last_10_rows)\n",
        "# Print the paragraph\n",
        "print(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFE_SwaSQSn8",
        "outputId": "743075d2-bc4b-4395-b344-dc1f1a63afc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28906"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(df1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ZEkhCcQSn8"
      },
      "source": [
        "# Split the English and Sinhala translation pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JTexDisnQSn8"
      },
      "outputs": [],
      "source": [
        "#common function for both spanish and german\n",
        "\n",
        "class split_pairs:\n",
        " def split_pairs_method(self,df1):\n",
        "  text_pairs=[]\n",
        "\n",
        "  for i in range(len(df1)):\n",
        "    english, language = df1[\"english\"][i], str(df1[\"sinhala\"][i])  # Convert to string\n",
        "    language=\"[start] \" + language + \" [end]\"\n",
        "    text_pairs.append((english,language))\n",
        "\n",
        "  return text_pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GxCLV26oQSn8"
      },
      "outputs": [],
      "source": [
        "#randomly selecting that if the above function work\n",
        "class random_pair_test:\n",
        "  def random_test_method(self,text_pairs):\n",
        "   for i in range(3):\n",
        "    print(random.choice(text_pairs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWz-4aHrQSn8",
        "outputId": "34fb218c-cd4a-473c-e7b7-f58d7c245726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Within days, Japan captured the American island of Guam.', '[start] දින කිහිපයක් ඇතුළත ජපානය ඇමරිකානු ගුවාම් විසින් ග්රහණය කර ගත්තේය. [end]')\n",
            "('Love is blind.', '[start] ආදරය අන්ධයි. [end]')\n",
            "(\"Tom is looking for someone to take Mary's place.\", '[start] ටොම් මරියාගේ ස්ථානය ගැනීමට කෙනෙකු සොයමින් සිටී. [end]')\n"
          ]
        }
      ],
      "source": [
        "#pairing for sinhala text\n",
        "\n",
        "sinhala_text_pairs=split_pairs().split_pairs_method(df1)\n",
        "\n",
        "random_pair_test().random_test_method(sinhala_text_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONBS7oUKQSn8"
      },
      "source": [
        "# Randomizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NMqM0bX4QSn9"
      },
      "outputs": [],
      "source": [
        "random.shuffle(sinhala_text_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9jf4gG5QSn9"
      },
      "source": [
        "# Split the data into training, validation,testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fu-sAp4xQSn9"
      },
      "outputs": [],
      "source": [
        "#class for splitting text pairs in to train,test,validation\n",
        "class splitting:\n",
        "    def splitting_method(self,text_pairs):\n",
        "        num_val_sample=int(0.15*len(text_pairs))\n",
        "        num_train_samples=len(text_pairs) - 2 * num_val_sample\n",
        "        train_pairs=text_pairs[:num_train_samples]\n",
        "        val_pairs=text_pairs[num_train_samples:num_train_samples+num_val_sample]\n",
        "        test_pairs=text_pairs[num_train_samples+num_val_sample:]\n",
        "\n",
        "        print(\"Total Sentences: \",len(text_pairs))\n",
        "        print(\"Training set size: \",len(train_pairs))\n",
        "        print(\"Validation set size: \",len(val_pairs))\n",
        "        print(\"Testng set size: \",len(test_pairs))\n",
        "        return train_pairs,val_pairs,test_pairs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CEDavS5QSn9",
        "outputId": "7d13ef42-d6ee-4e40-8eea-89881ea72928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sentences:  28906\n",
            "Training set size:  20236\n",
            "Validation set size:  4335\n",
            "Testng set size:  4335\n"
          ]
        }
      ],
      "source": [
        "sinhala_train_pairs,sinhala_val_pairs,sinhala_test_pairs=splitting().splitting_method(sinhala_text_pairs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pOw65VxQSn9",
        "outputId": "97413bcd-1024-45e6-8b5c-e621e429c896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28906\n"
          ]
        }
      ],
      "source": [
        "print(len(sinhala_test_pairs)+len(sinhala_train_pairs)+len(sinhala_val_pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b1WfhLtQSn9",
        "outputId": "341a1377-5784-409d-9f13-b0d211e19670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Not only were we hungry, but we were also suffering from thirst.', '[start] අපට බඩගිනවා පමණක් නොව, අපි ද පිපාසයෙන් පෙළුණා. [end]')\n"
          ]
        }
      ],
      "source": [
        "print(sinhala_val_pairs[200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aBuMqKeQSn9"
      },
      "source": [
        "# Removing Puncuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3VWCgQzrQSn-",
        "outputId": "981de2f4-8a70-4e73-ecf6-0cb0d377978d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "f\"[{re.escape(strip_chars)}]\"\n",
        "\n",
        "f\"{5+3}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC2pkVMvQSn-"
      },
      "source": [
        "# Vectorizing the English and Sinhala text pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bDTsAh84QSn-"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_string):\n",
        "    lowercase=tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase,f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size=15000\n",
        "sequence_length=20\n",
        "\n",
        "source_vectorization=layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "target_vectorization=layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length+1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_english_texts=[pair[0] for pair in sinhala_train_pairs]\n",
        "train_sinhala_texts=[pair[1] for pair in sinhala_train_pairs]\n",
        "\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_sinhala_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MOw15MTQSn-",
        "outputId": "66ff26df-e103-479a-8bf5-0f2388811f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the same car that was left at the scene of the crime.\n",
            "[start] අපරාධය ස්ථානයේ ඉතිරිව ඇති එකම මෝටර් රථය මෙයයි. [end]\n",
            "<keras.src.layers.preprocessing.text_vectorization.TextVectorization object at 0x7ce32f70fc10>\n"
          ]
        }
      ],
      "source": [
        "print(train_english_texts[1])\n",
        "print(train_sinhala_texts[1])\n",
        "\n",
        "print(source_vectorization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5sLgImmQSn-",
        "outputId": "1c6cfe02-4875-4785-cd44-1f3631e95423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This is the same car that was left at the scene of the crime.', '[start] අපරාධය ස්ථානයේ ඉතිරිව ඇති එකම මෝටර් රථය මෙයයි. [end]'), ('I watched you.', '[start] මම ඔයාව බැලුවා. [end]'), (\"I was going to try to get into Tokyo University, but I've changed my mind.\", '[start] මම ටෝකියෝ විශ්ව විද්යාලයට ඇතුල් වීමට උත්සාහ කළා, නමුත් මම මගේ අදහස වෙනස් කළා. [end]'), ('I hate Sundays.', '[start] මම ඉරිදාට වෛර කරනවා. [end]')]\n"
          ]
        }
      ],
      "source": [
        "print(sinhala_train_pairs[1:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3s0jIZsQSn-"
      },
      "source": [
        "# Preparing datasets for the translation task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t-RDOfPQSn_",
        "outputId": "c5a0a15c-16e7-4225-e043-06b755ccfd8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['german'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "batch_size=64\n",
        "\n",
        "def format_dataset(eng,ger):\n",
        "    eng=source_vectorization(eng)\n",
        "    ger=target_vectorization(ger)\n",
        "    return ({\"english\":eng,\n",
        "             \"german\":ger[:,:-1],\n",
        "             },ger[:,1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts,ger_texts=zip(*pairs)\n",
        "    eng_texts=list(eng_texts)\n",
        "    ger_texts=list(ger_texts)\n",
        "    dataset=tf.data.Dataset.from_tensor_slices((eng_texts,ger_texts))\n",
        "    dataset=dataset.batch(batch_size)\n",
        "    dataset=dataset.map(format_dataset,num_parallel_calls=4)\n",
        "\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_data=make_dataset(sinhala_train_pairs)\n",
        "val_data=make_dataset(sinhala_val_pairs)\n",
        "\n",
        "# print(train_data)\n",
        "# print(val_data)\n",
        "\n",
        "for inputs, targets in train_data.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['german'].shape: {inputs['german'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQVEkF7oQSn_",
        "outputId": "3df010ae-4193-4e9a-9264-58e2aadc8fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'english': array([[  15, 1015,  139, ...,    0,    0,    0],\n",
            "       [  25, 2512,   30, ...,    0,    0,    0],\n",
            "       [   5,   14,  908, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   3,  105,  727, ...,    0,    0,    0],\n",
            "       [   3,   40,   15, ...,    0,    0,    0],\n",
            "       [   5,  659,    2, ...,    0,    0,    0]]), 'german': array([[   2,   10, 1284, ...,    0,    0,    0],\n",
            "       [   2,   14,    7, ...,    0,    0,    0],\n",
            "       [   2,    5, 4763, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,    4, 3296, ...,    0,    0,    0],\n",
            "       [   2,    6,   10, ...,    0,    0,    0],\n",
            "       [   2,    5, 4427, ...,    0,    0,    0]])}, array([[  10, 1284, 3492, ...,    0,    0,    0],\n",
            "       [  14,    7,  169, ...,    0,    0,    0],\n",
            "       [   5, 4763, 2424, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   4, 3296,    3, ...,    0,    0,    0],\n",
            "       [   6,   10, 3150, ...,    0,    0,    0],\n",
            "       [   5, 4427, 2054, ...,    0,    0,    0]]))\n"
          ]
        }
      ],
      "source": [
        "print(list(train_data.as_numpy_iterator())[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4FpSuqPQSn_"
      },
      "source": [
        "# Transformers encoder implemented as a subclassed Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nyRAeFDgQSn_"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self,embed_dim,dense_dim,num_heads,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim=embed_dim\n",
        "        self.dense_dim=dense_dim\n",
        "        self.num_heads=num_heads\n",
        "        self.attention=layers.MultiHeadAttention(\n",
        "           num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.dense_proj=keras.Sequential(\n",
        "            [layers.Dense(dense_dim,activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1=layers.LayerNormalization()\n",
        "        self.layernorm_2=layers.LayerNormalization()\n",
        "\n",
        "    def call(self,inputs,mask=None):\n",
        "        if mask is not None:\n",
        "            mask=mask[:,tf.newaxis,:]\n",
        "        attention_output=self.attention(\n",
        "            inputs,inputs,attention_mask=mask\n",
        "        )\n",
        "        project_input=self.layernorm_1(inputs+attention_output)\n",
        "        project_output=self.dense_proj(project_input)\n",
        "\n",
        "        return self.layernorm_2(project_input+project_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config=super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asuNvD-cQSn_"
      },
      "source": [
        "# Transformer decorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vP9OTqcxQSn_"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self,embed_dim,dense_dim,num_heads,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim=embed_dim\n",
        "        self.dense_dim=dense_dim\n",
        "        self.num_heads=num_heads\n",
        "        self.attention_1=layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.attention_2=layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.dense_proj=keras.Sequential(\n",
        "            [layers.Dense(dense_dim,activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1=layers.LayerNormalization()\n",
        "        self.layernorm_2=layers.LayerNormalization()\n",
        "        self.layernorm_3=layers.LayerNormalization()\n",
        "        self.supports_masking=True\n",
        "\n",
        "    def get_config(self):\n",
        "        config=super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_casual_attention_mask(self,inputs):\n",
        "        input_shape=tf.shape(inputs)\n",
        "        batch_size,sequence_length=input_shape[0],input_shape[1]\n",
        "        i=tf.range(sequence_length)[:,tf.newaxis]\n",
        "        j=tf.range(sequence_length)\n",
        "        mask=tf.cast(i>=j,dtype=\"int32\")\n",
        "        mask=tf.reshape(mask,(1,input_shape[1],input_shape[1]))\n",
        "        mult=tf.concat(\n",
        "            [tf.expand_dims(batch_size,-1),\n",
        "             tf.constant([1,1],dtype=tf.int32)],axis=0)\n",
        "\n",
        "        return tf.tile(mask,mult)\n",
        "\n",
        "\n",
        "    def call(self,inputs,encorder_outputs,mask=None):\n",
        "        casual_mask=self.get_casual_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask=tf.cast(\n",
        "                mask[:,tf.newaxis,:],dtype=\"int32\"\n",
        "            )\n",
        "            padding_mask=tf.minimum(padding_mask,casual_mask)\n",
        "        else:\n",
        "            padding_mask=mask\n",
        "        attention_output_1=self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=casual_mask\n",
        "        )\n",
        "        attention_output_1=self.layernorm_1(inputs+attention_output_1)\n",
        "        attention_output_2=self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encorder_outputs,\n",
        "            key=encorder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2=self.layernorm_2(\n",
        "            attention_output_1+attention_output_2\n",
        "        )\n",
        "        proj_output=self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2+proj_output)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0Dt2Pj_QSoA"
      },
      "source": [
        "# Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "W8JH3MDzQSoA"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self,sequence_length,input_dim,output_dim,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings=layers.Embedding(\n",
        "            input_dim=input_dim,output_dim=output_dim)\n",
        "        self.position_embeddings=layers.Embedding(\n",
        "            input_dim=sequence_length,output_dim=output_dim)\n",
        "        self.sequence_length=sequence_length\n",
        "        self.input_dim=input_dim\n",
        "        self.output_dim=output_dim\n",
        "\n",
        "    def call(self,inputs):\n",
        "        length=tf.shape(inputs)[-1]\n",
        "        positions=tf.range(start=0,limit=length,delta=1)\n",
        "        embedded_tokens=self.token_embeddings(inputs)\n",
        "        embedded_positions=self.position_embeddings(positions)\n",
        "\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config=super(PositionalEmbedding,self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OJz24S2XQSoH"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.python.framework.ops import disable_eager_execution\n",
        "# disable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZN5UgCOQSoH"
      },
      "source": [
        "# End-to-End Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QYCGfZpwQSoH"
      },
      "outputs": [],
      "source": [
        "embed_dim=256\n",
        "dense_dim=2048\n",
        "num_heads=8\n",
        "\n",
        "encoder_inputs=keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x=PositionalEmbedding(sequence_length,vocab_size,embed_dim)(encoder_inputs)\n",
        "encoder_outputs=TransformerEncoder(embed_dim,dense_dim,num_heads)(x)\n",
        "\n",
        "decorder_inputs=keras.Input(shape=(None,),dtype=\"int64\",name=\"sinhala\")\n",
        "x=PositionalEmbedding(sequence_length,vocab_size,embed_dim)(decorder_inputs)\n",
        "x=TransformerDecoder(embed_dim,dense_dim,num_heads)(x,encoder_outputs)\n",
        "x=layers.Dropout(0.5)(x)\n",
        "decorder_outputs=layers.Dense(vocab_size,activation=\"softmax\")(x)\n",
        "transformer=keras.Model([encoder_inputs,decorder_inputs],decorder_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XepQ7qXITPOP"
      },
      "source": [
        "# Training the sequence-to-sequence Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_IQ5KACSRIa",
        "outputId": "1c107356-fe35-444c-d1f7-71e99e926d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " sinhala (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Po  (None, None, 256)            3845120   ['english[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " positional_embedding_3 (Po  (None, None, 256)            3845120   ['sinhala[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Tra  (None, None, 256)            3155456   ['positional_embedding_2[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder_1 (Tra  (None, None, 256)            5259520   ['positional_embedding_3[0][0]\n",
            " nsformerDecoder)                                                   ',                            \n",
            "                                                                     'transformer_encoder_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 256)            0         ['transformer_decoder_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, None, 15000)          3855000   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19960216 (76.14 MB)\n",
            "Trainable params: 19960216 (76.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFQ2g7CYSdft",
        "outputId": "bc52e62e-5094-4d10-bff1-3ab535d52007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "317/317 [==============================] - 39s 96ms/step - loss: 5.5004 - accuracy: 0.3130 - val_loss: 4.7711 - val_accuracy: 0.3683\n",
            "Epoch 2/50\n",
            "317/317 [==============================] - 21s 66ms/step - loss: 4.4595 - accuracy: 0.3886 - val_loss: 4.2214 - val_accuracy: 0.4160\n",
            "Epoch 3/50\n",
            "317/317 [==============================] - 21s 65ms/step - loss: 3.9244 - accuracy: 0.4387 - val_loss: 3.9326 - val_accuracy: 0.4483\n",
            "Epoch 4/50\n",
            "317/317 [==============================] - 21s 66ms/step - loss: 3.5416 - accuracy: 0.4759 - val_loss: 3.7422 - val_accuracy: 0.4704\n",
            "Epoch 5/50\n",
            "317/317 [==============================] - 22s 68ms/step - loss: 3.2268 - accuracy: 0.5081 - val_loss: 3.6573 - val_accuracy: 0.4819\n",
            "Epoch 6/50\n",
            "317/317 [==============================] - 22s 68ms/step - loss: 2.9708 - accuracy: 0.5361 - val_loss: 3.5583 - val_accuracy: 0.4930\n",
            "Epoch 7/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 2.7620 - accuracy: 0.5617 - val_loss: 3.5750 - val_accuracy: 0.4961\n",
            "Epoch 8/50\n",
            "317/317 [==============================] - 22s 70ms/step - loss: 2.5842 - accuracy: 0.5836 - val_loss: 3.5365 - val_accuracy: 0.5034\n",
            "Epoch 9/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 2.4284 - accuracy: 0.6048 - val_loss: 3.5050 - val_accuracy: 0.5109\n",
            "Epoch 10/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 2.3093 - accuracy: 0.6213 - val_loss: 3.5443 - val_accuracy: 0.5122\n",
            "Epoch 11/50\n",
            "317/317 [==============================] - 22s 70ms/step - loss: 2.2022 - accuracy: 0.6388 - val_loss: 3.5336 - val_accuracy: 0.5138\n",
            "Epoch 12/50\n",
            "317/317 [==============================] - 22s 70ms/step - loss: 2.1180 - accuracy: 0.6510 - val_loss: 3.5661 - val_accuracy: 0.5146\n",
            "Epoch 13/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 2.0418 - accuracy: 0.6649 - val_loss: 3.5435 - val_accuracy: 0.5196\n",
            "Epoch 14/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.9864 - accuracy: 0.6757 - val_loss: 3.5904 - val_accuracy: 0.5123\n",
            "Epoch 15/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.9346 - accuracy: 0.6863 - val_loss: 3.5907 - val_accuracy: 0.5172\n",
            "Epoch 16/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.9007 - accuracy: 0.6939 - val_loss: 3.6185 - val_accuracy: 0.5213\n",
            "Epoch 17/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.8603 - accuracy: 0.7040 - val_loss: 3.6640 - val_accuracy: 0.5160\n",
            "Epoch 18/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.8332 - accuracy: 0.7100 - val_loss: 3.6779 - val_accuracy: 0.5158\n",
            "Epoch 19/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.8105 - accuracy: 0.7171 - val_loss: 3.6809 - val_accuracy: 0.5181\n",
            "Epoch 20/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.7850 - accuracy: 0.7235 - val_loss: 3.7168 - val_accuracy: 0.5206\n",
            "Epoch 21/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.7645 - accuracy: 0.7289 - val_loss: 3.7221 - val_accuracy: 0.5223\n",
            "Epoch 22/50\n",
            "317/317 [==============================] - 22s 68ms/step - loss: 1.7478 - accuracy: 0.7333 - val_loss: 3.7411 - val_accuracy: 0.5191\n",
            "Epoch 23/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.7279 - accuracy: 0.7394 - val_loss: 3.7910 - val_accuracy: 0.5154\n",
            "Epoch 24/50\n",
            "317/317 [==============================] - 22s 70ms/step - loss: 1.7167 - accuracy: 0.7440 - val_loss: 3.7942 - val_accuracy: 0.5213\n",
            "Epoch 25/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.6985 - accuracy: 0.7484 - val_loss: 3.8319 - val_accuracy: 0.5183\n",
            "Epoch 26/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.6847 - accuracy: 0.7521 - val_loss: 3.8295 - val_accuracy: 0.5199\n",
            "Epoch 27/50\n",
            "317/317 [==============================] - 23s 72ms/step - loss: 1.6722 - accuracy: 0.7556 - val_loss: 3.8529 - val_accuracy: 0.5199\n",
            "Epoch 28/50\n",
            "317/317 [==============================] - 24s 74ms/step - loss: 1.6650 - accuracy: 0.7574 - val_loss: 3.8436 - val_accuracy: 0.5221\n",
            "Epoch 29/50\n",
            "317/317 [==============================] - 23s 73ms/step - loss: 1.6522 - accuracy: 0.7623 - val_loss: 3.9119 - val_accuracy: 0.5185\n",
            "Epoch 30/50\n",
            "317/317 [==============================] - 23s 71ms/step - loss: 1.6393 - accuracy: 0.7652 - val_loss: 3.8800 - val_accuracy: 0.5239\n",
            "Epoch 31/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.6276 - accuracy: 0.7689 - val_loss: 3.9064 - val_accuracy: 0.5243\n",
            "Epoch 32/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.6182 - accuracy: 0.7708 - val_loss: 3.9452 - val_accuracy: 0.5219\n",
            "Epoch 33/50\n",
            "317/317 [==============================] - 22s 70ms/step - loss: 1.6118 - accuracy: 0.7734 - val_loss: 3.9889 - val_accuracy: 0.5193\n",
            "Epoch 34/50\n",
            "317/317 [==============================] - 26s 83ms/step - loss: 1.6019 - accuracy: 0.7759 - val_loss: 3.9957 - val_accuracy: 0.5226\n",
            "Epoch 35/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.5976 - accuracy: 0.7773 - val_loss: 3.9671 - val_accuracy: 0.5226\n",
            "Epoch 36/50\n",
            "317/317 [==============================] - 22s 70ms/step - loss: 1.5882 - accuracy: 0.7797 - val_loss: 4.0066 - val_accuracy: 0.5228\n",
            "Epoch 37/50\n",
            "317/317 [==============================] - 23s 73ms/step - loss: 1.5780 - accuracy: 0.7815 - val_loss: 4.1226 - val_accuracy: 0.5149\n",
            "Epoch 38/50\n",
            "317/317 [==============================] - 22s 71ms/step - loss: 1.5752 - accuracy: 0.7834 - val_loss: 4.0549 - val_accuracy: 0.5200\n",
            "Epoch 39/50\n",
            "317/317 [==============================] - 22s 70ms/step - loss: 1.5640 - accuracy: 0.7858 - val_loss: 4.0828 - val_accuracy: 0.5217\n",
            "Epoch 40/50\n",
            "317/317 [==============================] - 22s 71ms/step - loss: 1.5552 - accuracy: 0.7881 - val_loss: 4.1227 - val_accuracy: 0.5191\n",
            "Epoch 41/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.5547 - accuracy: 0.7883 - val_loss: 4.1268 - val_accuracy: 0.5222\n",
            "Epoch 42/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.5464 - accuracy: 0.7911 - val_loss: 4.1381 - val_accuracy: 0.5226\n",
            "Epoch 43/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.5379 - accuracy: 0.7925 - val_loss: 4.1615 - val_accuracy: 0.5211\n",
            "Epoch 44/50\n",
            "317/317 [==============================] - 23s 72ms/step - loss: 1.5331 - accuracy: 0.7934 - val_loss: 4.1281 - val_accuracy: 0.5251\n",
            "Epoch 45/50\n",
            "317/317 [==============================] - 24s 74ms/step - loss: 1.5315 - accuracy: 0.7945 - val_loss: 4.1679 - val_accuracy: 0.5246\n",
            "Epoch 46/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.5214 - accuracy: 0.7968 - val_loss: 4.2161 - val_accuracy: 0.5183\n",
            "Epoch 47/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.5200 - accuracy: 0.7977 - val_loss: 4.2086 - val_accuracy: 0.5223\n",
            "Epoch 48/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.5171 - accuracy: 0.7987 - val_loss: 4.2609 - val_accuracy: 0.5179\n",
            "Epoch 49/50\n",
            "317/317 [==============================] - 22s 69ms/step - loss: 1.5053 - accuracy: 0.8002 - val_loss: 4.2135 - val_accuracy: 0.5200\n",
            "Epoch 50/50\n",
            "317/317 [==============================] - 22s 68ms/step - loss: 1.4984 - accuracy: 0.8017 - val_loss: 4.2466 - val_accuracy: 0.5212\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ce2ae740e50>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "transformer.fit(train_data,epochs=50,validation_data=val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "C0zjU_ZqagVO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "sinahala_vocab = target_vectorization.get_vocabulary()\n",
        "sinahala_index_lookup = dict(zip(range(len(sinahala_vocab)), sinahala_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = sinahala_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "PY_wqakzcGB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc7050a-4ab4-4061-c756-f6af1dce45ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "What have you got?\n",
            "[start] ඔබට ඇත්තේ කුමක්ද [end]\n",
            "-\n",
            "Cheating on one's spouse is not usually considered acceptable behavior.\n",
            "[start] සීයා සහ කකුල් විවාහ ගිවිසගෙන සිටී [end]\n",
            "-\n",
            "Tom finally realized there was something wrong.\n",
            "[start] ටොම් ඉතා භයානක දෙයක් හරි බවට පත්විය [end]\n",
            "-\n",
            "Always keep a bucket of water handy, in case of fire.\n",
            "[start] සෑම විටම මා සතුව ඇති එය වහාම ජලය හිස් අවශ්යය [end]\n",
            "-\n",
            "I wish I could do everything that I wanted to do.\n",
            "[start] මට අවශ්ය නම් මට කළ හැකි කිරීම සඳහා එය කිරීම හොඳයි [end]\n",
            "-\n",
            "It was like that.\n",
            "[start] එය ඒ වගේ [end]\n",
            "-\n",
            "Since I'm not so good at swimming, I avoid swimming in water that's over my head.\n",
            "[start] මම හොඳයි එය බේස්බෝල් බැලීමට තරම් කුඩා බැවින් මට කාලගුණය සීතල වූ නිසා මම හිතුවේ නැහැ [end]\n",
            "-\n",
            "No matter how many people tell him he made a mistake, Tom still insists he's right.\n",
            "[start] ටොම් කොතරම් විභාගය ඔහු කිසි විටෙකත් භයානක දෙයක් පැවසිය යුතු බව ඔහු පෙනී සිටිනු ඇත [end]\n",
            "-\n",
            "I waited half an hour for my friend, but he didn't turn up.\n",
            "[start] ඔහු මගේ මිතුරෙකු පිටත්ව යාමට පැය තුනක් තිස්සේ මගේ මිතුරෙකු පිටත්ව පෙනී සිටීමට කැමති නැත [end]\n",
            "-\n",
            "Be careful.\n",
            "[start] බරපතල වන්න [end]\n",
            "-\n",
            "I didn't quit.\n",
            "[start] මම ඇයව පිටත්ව ගියා [end]\n",
            "-\n",
            "It only took us fifteen minutes to complete the job.\n",
            "[start] අප රථවාහන එක වෙනුවට එය මිනිත්තු 20 කින් පමණි [end]\n",
            "-\n",
            "I was an idiot.\n",
            "[start] මට මෝඩයෙක් විය [end]\n",
            "-\n",
            "The Panama Canal connects the Atlantic with the Pacific.\n",
            "[start] නැව විශාල අයිස් ඉහළට හැර ගියේය [end]\n",
            "-\n",
            "The invention of TV caused a drastic change in our daily life.\n",
            "[start] අපේ සිටිමු ඔබට රූපවාහිනිය නරඹමින් සිටියේ තව ටිකක් වෙනස් කිරීමට කළේ වයස අවුරුදු කීයක් ගත හැකිය [end]\n",
            "-\n",
            "Do you like rap?\n",
            "[start] ඔබ යුෂ වලට කැමතිද [end]\n",
            "-\n",
            "He is at his desk.\n",
            "[start] ඔහු ඔහුගේ මේසය මත ඇත [end]\n",
            "-\n",
            "Tom is the only American Mary knows whose father wasn't born in America.\n",
            "[start] ඔහු නිෂ්පාදනය කරන එකම රැස්වීම අපේ පියා ඔබ ජීවතුන් අතර පමණි [end]\n",
            "-\n",
            "Japan is in Asia.\n",
            "[start] ජපානය ජපානයේ විශාලතම [end]\n",
            "-\n",
            "Tom wasn't about to leave Mary alone with John.\n",
            "[start] ටොම් ජෝන් සමඟ මරියා සමඟ පිටත්ව යාමට සූදානම්ව සිටියේ නැත [end]\n"
          ]
        }
      ],
      "source": [
        "ger_eng_texts = [pair[0] for pair in sinhala_test_pairs]\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(ger_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_YFgoVCYl_zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b231396-6df3-4286-f9ff-5b5e57811563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5ERUlhqdmwhn"
      },
      "outputs": [],
      "source": [
        "# transformer.save('/content/drive/My Drive/Translators')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# New 20 Observations\n"
      ],
      "metadata": {
        "id": "_mFTqFKbcwby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_english_sentences = [\"Wheat is the primary grain cultivated in the Midwest.\",\n",
        "\"Would you mind dropping by my cubicle when you get a chance?\",\n",
        "\"Received any New Year's gifts from Sarah this time around?\",\n",
        "\"Have you caught wind of the incident involving Tom and Mary?\",\n",
        "\"Embrace uncertainty, but always stay prepared for it.\",\n",
        "\"Make the best out of what you possess, wherever you may be.\",\n",
        "\"Can you pick up on any sounds coming from the adjacent room?\",\n",
        "\"Aware of the fine line between right and wrong?\",\n",
        "\"Do you believe she's entirely innocent in this matter?\",\n",
        "\"Does the level of humidity impact plant growth significantly?\",\n",
        "\"Remember your raincoat when stepping out; the forecast is uncertain.\",\n",
        "\"Avoid delaying tasks; accomplish what's within your reach today.\",\n",
        "\"Keep out of other people's affairs; it's not your place.\",\n",
        "\"Rest assured, Tom can handle himself just fine.\",\n",
        "\"No need to worry about my dog; he poses no threat to you.\",\n",
        "\"Exercise caution while driving, lest you meet with an accident.\",\n",
        "\"Endured many hardships during the turbulent years of conflict.\",\n",
        "\"This image triggers memories of my father each time I gaze upon it.\",\n",
        "\"Distinguishable by their distinctive features, elephants belong to three distinct species.\",\n",
        "\"Elephants rank as the largest terrestrial animals on the planet.\"]"
      ],
      "metadata": {
        "id": "UC8O0CWhdGly"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(custom_english_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alSsOut74VJL",
        "outputId": "51433937-410e-4cd9-a95c-ce924fac3569"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wheat is the primary grain cultivated in the Midwest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in custom_english_sentences:\n",
        "    print(\"Original English Sentence:\", sentence)\n",
        "    translated_sentence = decode_sequence(sentence)\n",
        "    print(\"Translated Sinhala Sentence:\", translated_sentence)\n",
        "    print(\"-\" * 20)  # Separator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRi7Ykgc42mN",
        "outputId": "6fbf7144-c17a-4590-e59b-7e4a2dfcfbe2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original English Sentence: Wheat is the primary grain cultivated in the Midwest.\n",
            "Translated Sinhala Sentence: [start] නැව විශාල අයිස් න එක විශේෂ විහිළුවක් [end]\n",
            "--------------------\n",
            "Original English Sentence: Would you mind dropping by my cubicle when you get a chance?\n",
            "Translated Sinhala Sentence: [start] ඔබට නිවාඩුවක් දිය හැකි විට ඔබේ ඇඳුම් ඔබට දිය යුතුද [end]\n",
            "--------------------\n",
            "Original English Sentence: Received any New Year's gifts from Sarah this time around?\n",
            "Translated Sinhala Sentence: [start] මෙම නව යම් මුදලක් ඉල්ලා සිටීමට තීරණය කර ඇත [end]\n",
            "--------------------\n",
            "Original English Sentence: Have you caught wind of the incident involving Tom and Mary?\n",
            "Translated Sinhala Sentence: [start] ඔබ සහ ටොම් මරියා කුඩා කළේ එයයි [end]\n",
            "--------------------\n",
            "Original English Sentence: Embrace uncertainty, but always stay prepared for it.\n",
            "Translated Sinhala Sentence: [start] සඳහා දොර වසා දැමීමට අමතක කිරීම සඳහා එය නිතරම සිතමි [end]\n",
            "--------------------\n",
            "Original English Sentence: Make the best out of what you possess, wherever you may be.\n",
            "Translated Sinhala Sentence: [start] ඔබ බවට පත් වුවද ඔබ පුවත්පත් බෑගය සොයා කරනු ඇත [end]\n",
            "--------------------\n",
            "Original English Sentence: Can you pick up on any sounds coming from the adjacent room?\n",
            "Translated Sinhala Sentence: [start] ඔබට දොරට එකක් හෝ මීට වසර ගණනාවක් තිස්සේ පිටුපස තබන්න පුළුවන්ද [end]\n",
            "--------------------\n",
            "Original English Sentence: Aware of the fine line between right and wrong?\n",
            "Translated Sinhala Sentence: [start] හරි දේ ගැන හරි බව මට දැන ගන්න [end]\n",
            "--------------------\n",
            "Original English Sentence: Do you believe she's entirely innocent in this matter?\n",
            "Translated Sinhala Sentence: [start] මෙම ගීතය දුන්නේය [end]\n",
            "--------------------\n",
            "Original English Sentence: Does the level of humidity impact plant growth significantly?\n",
            "Translated Sinhala Sentence: [start] නැව විශාල ප්රමාණයක් ගත් කල ඔහු නරක පැමිණෙනු ඇත [end]\n",
            "--------------------\n",
            "Original English Sentence: Remember your raincoat when stepping out; the forecast is uncertain.\n",
            "Translated Sinhala Sentence: [start] මතක තබා ගැනීම ඔබේ පුවත්පත් එකතු වී ඇත්තේ කුමක්ද [end]\n",
            "--------------------\n",
            "Original English Sentence: Avoid delaying tasks; accomplish what's within your reach today.\n",
            "Translated Sinhala Sentence: [start] එය හේතුව ඔබේ පුවත්පත් ලිපිය ලිවීමට භාවිතා කරන ඔහු ප්රශ්නයක් නොවේ [end]\n",
            "--------------------\n",
            "Original English Sentence: Keep out of other people's affairs; it's not your place.\n",
            "Translated Sinhala Sentence: [start] ඔබේ දරුවන් සමඟ වෙනත් කෙනෙකුට එකඟ නොවන බව මතක තබා ගන්න [end]\n",
            "--------------------\n",
            "Original English Sentence: Rest assured, Tom can handle himself just fine.\n",
            "Translated Sinhala Sentence: [start] ටොම් තනිවම එය හොඳින් කරන ලෙස කථා කළ හැකිය [end]\n",
            "--------------------\n",
            "Original English Sentence: No need to worry about my dog; he poses no threat to you.\n",
            "Translated Sinhala Sentence: [start] ටොම් සඳහා මගේ බල්ලා ගැන කරදර නොවන්නේ ඔහු ඔබට උදව් කිරීමට අවශ්යයි [end]\n",
            "--------------------\n",
            "Original English Sentence: Exercise caution while driving, lest you meet with an accident.\n",
            "Translated Sinhala Sentence: [start] ටොම්ව අනතුර ඔබ රෝහලට ගෙන ඇති විට යමෙකු රෝහලට ගෙන පැමිණෙනු ඇත [end]\n",
            "--------------------\n",
            "Original English Sentence: Endured many hardships during the turbulent years of conflict.\n",
            "Translated Sinhala Sentence: [start] වසර තුළ ජනගහනය එක්සත් ජනපදයේ බොහෝ කාලයක් තිස්සේ ඔවුන් ජනතාව ඇවිද ගොස් ඇත [end]\n",
            "--------------------\n",
            "Original English Sentence: This image triggers memories of my father each time I gaze upon it.\n",
            "Translated Sinhala Sentence: [start] මෙම ඡායාරූපය සෑම විටම මගේ ආච්චි ඔහුට අවශ්ය නොවූ බව මා කුඩා වේ [end]\n",
            "--------------------\n",
            "Original English Sentence: Distinguishable by their distinctive features, elephants belong to three distinct species.\n",
            "Translated Sinhala Sentence: [start] තර්ක කිරීම සඳහා ජනතාව ගමනක් පසු ජනතාව කියන්න ඔවුන්ගේ ජනතාව සඳහා ඔවුන්ගේ වෙන් කළේය [end]\n",
            "--------------------\n",
            "Original English Sentence: Elephants rank as the largest terrestrial animals on the planet.\n",
            "Translated Sinhala Sentence: [start] පුවත්පත් යනු දැන මෙතැන් සිට යනු තවමත් වැස්ස ඉතා අපට වහාම ය [end]\n",
            "--------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}